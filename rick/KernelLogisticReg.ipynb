{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of SPectrum Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#spectrum kernel implem\n",
    "#saw it in ALM course\n",
    "\n",
    "\n",
    "def getSubString(mString, spectrum):\n",
    "    \"\"\"\n",
    "    get substrings of length spectrum\n",
    "    \n",
    "    Attributes:\n",
    "        mstring: the string to subdivise\n",
    "        spectrum : the length of the substrings\n",
    "    return :\n",
    "        substrings of length spectrum\n",
    "    \"\"\"\n",
    "    tmpList = []\n",
    "    mString = mString.lower()\n",
    "    if (spectrum == 0):\n",
    "        tmpList = ['']\n",
    "    else:\n",
    "        for i in range(len(mString)-spectrum+1):\n",
    "            mStringRes = ''\n",
    "            for j in range(spectrum):\n",
    "                mStringRes += mString[i+j]\n",
    "            tmpList.append(mStringRes)\n",
    "    return tmpList\n",
    "\n",
    "def pSpectrumKernelFunction(mString1, mString2, spectrum):\n",
    "    \"\"\"\n",
    "    compute the spectrum kernel of two strings\n",
    "   \n",
    "    Attributes:\n",
    "        mstring1 : the first string\n",
    "        mstring2: the second string\n",
    "        spectrum : the length of substrings(spectrum used)\n",
    "    return :\n",
    "        spectrum kernel value\n",
    "    \"\"\"\n",
    "    \n",
    "    subString1 = getSubString(mString1, spectrum)\n",
    "    subString2 = getSubString(mString2, spectrum)\n",
    "    kernel = 0\n",
    "    for i in subString1:\n",
    "        for j in subString2:\n",
    "            if (i==j):\n",
    "                kernel += 1\n",
    "    return kernel\n",
    "\n",
    "def _gram_matrix_element(mString1, mString2, spectrum, sdkvalue1, sdkvalue2):\n",
    "    \"\"\"\n",
    "        compute the element K(i,j) of a gram matrix\n",
    "        normalize spectrum kernel are used Knorm(i,j) = K(i,j)/(K(i,i)*K(j,j))^O.5\n",
    "        \n",
    "        Attributes:\n",
    "            mstring1, mstring2: strings for which we compute the kernel\n",
    "            sdkvalue1, sdvalue2: K(mString1,mString1) and K(mString2,mString2) are diagonal \n",
    "                                  elements of K\n",
    "    \"\"\"\n",
    "    if mString1 == mString2:\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            return pSpectrumKernelFunction(mString1, mString2, spectrum) / \\\n",
    "                       (sdkvalue1 * sdkvalue2) ** 0.5\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Maximal subsequence length is less or equal to documents' minimal length.\"\n",
    "                      \"You should decrease it\")\n",
    "            sys.exit(2)\n",
    "            \n",
    "def computeKernelMatrix(X1, X2, spectrum):\n",
    "    \"\"\"\n",
    "    spectrum Kernel computation\n",
    "    Attributes:\n",
    "        param X: list of DNAs (m rows, 1 column); each row is a single DNA (string)\n",
    "        return: Gram matrix for the given parameters\n",
    "    \"\"\"\n",
    "    len_X1 = len(X1)\n",
    "    len_X2 = len(X2)\n",
    "    \n",
    "    # numpy array of Gram matrix\n",
    "    gram_matrix = np.zeros((len_X1, len_X2), dtype=np.float32)\n",
    "    sim_docs_kernel_value = {}\n",
    "    #when lists of documents are identical\n",
    "    if (X1==X2).all():\n",
    "    #store K(s,s) values in dictionary to avoid recalculations\n",
    "        for i in range(len_X1):\n",
    "#             print(\"ii\",i)\n",
    "            sim_docs_kernel_value[i] = pSpectrumKernelFunction(X1.item(i), X1.item(i), spectrum)\n",
    "        #calculate Gram matrix\n",
    "        for i in range(len_X1):\n",
    "#             print(\"i\",i)\n",
    "            for j in range(i, len_X2):\n",
    "                if(i==j):\n",
    "                    gram_matrix[i, j] = 1.0\n",
    "                else:\n",
    "                    gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), spectrum, sim_docs_kernel_value[i]\n",
    "                                                                 ,sim_docs_kernel_value[j])\n",
    "            #using symmetry\n",
    "                    gram_matrix[j, i] = gram_matrix[i, j]\n",
    "        \n",
    "    #when lists of documents are not identical but of the same length\n",
    "    elif len_X1 == len_X2:\n",
    "        sim_docs_kernel_value[1] = {}\n",
    "        sim_docs_kernel_value[2] = {}\n",
    "        #store K(s,s) values in dictionary to avoid recalculations\n",
    "        for i in range(len_X1):\n",
    "            sim_docs_kernel_value[1][i] = pSpectrumKernelFunction(X1.item(i), X1.item(i), spectrum)\n",
    "        for i in range(len_X2):\n",
    "            sim_docs_kernel_value[2][i] = pSpectrumKernelFunction(X2.item(i), X2.item(i), spectrum)\n",
    "        #calculate Gram matrix\n",
    "        for i in range(len_X1):\n",
    "#             print(\"ilen\",i)\n",
    "            for j in range(i, len_X2):\n",
    "                gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), spectrum, sim_docs_kernel_value[1][i],\n",
    "                                                             sim_docs_kernel_value[2][j])\n",
    "        #using symmetry\n",
    "                gram_matrix[j, i] = gram_matrix[i, j]\n",
    "    \n",
    "    #when lists of documents are neither identical nor of the same length\n",
    "    else:\n",
    "        sim_docs_kernel_value[1] = {}\n",
    "        sim_docs_kernel_value[2] = {}\n",
    "        min_dimens = min(len_X1, len_X2)\n",
    "        #store K(s,s) values in dictionary to avoid recalculations\n",
    "        for i in range(len_X1):\n",
    "            sim_docs_kernel_value[1][i] = pSpectrumKernelFunction(X1.item(i), X1.item(i), spectrum)\n",
    "        for i in range(len_X2):\n",
    "            sim_docs_kernel_value[2][i] = pSpectrumKernelFunction(X2.item(i), X2.item(i), spectrum)\n",
    "        #calculate Gram matrix for square part of rectangle matrix\n",
    "        for i in range(min_dimens):\n",
    "#             print(\"ielse1\",i)\n",
    "            for j in range(i, min_dimens):\n",
    "                gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), spectrum, sim_docs_kernel_value[1][i],\n",
    "                                                             sim_docs_kernel_value[2][j])\n",
    "                    #using symmetry\n",
    "                gram_matrix[j, i] = gram_matrix[i, j]\n",
    "\n",
    "        #if more rows than columns\n",
    "        if len_X1 > len_X2:\n",
    "            for i in range(min_dimens, len_X1):\n",
    "                for j in range(len_X2):\n",
    "                    gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), sim_docs_kernel_value[1][i],\n",
    "                                                                 sim_docs_kernel_value[2][j])\n",
    "        #if more columns than rows\n",
    "            \n",
    "        else:\n",
    "            for i in range(len_X1):\n",
    "#                 print(\"ielse2\",i)\n",
    "                for j in range(min_dimens, len_X2):\n",
    "                    gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j),spectrum, sim_docs_kernel_value[1][i],\n",
    "                                                                 sim_docs_kernel_value[2][j])\n",
    "    return gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression implementation\n",
    "from scipy import optimize as op #I read that we can use optimization library so... \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "#Regularized cost function\n",
    "def regCostFunction(theta, X, y, _lambda = 0.01):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X,theta))\n",
    "    tmp = np.copy(theta)\n",
    "    tmp[0] = 0 \n",
    "    reg = (_lambda/(2*m)) * np.sum(tmp**2)\n",
    "\n",
    "    return (1 / m) * (-y.T.dot(np.log(h)) - (1 - y).T.dot(np.log(1 - h))) + reg\n",
    "\n",
    "#Regularized gradient function\n",
    "def regGradient(theta, X, y, _lambda = 0.1):\n",
    "    m, n = X.shape\n",
    "    theta = theta.reshape((n, 1))\n",
    "    y = y.values.reshape((m, 1))\n",
    "    h = sigmoid(np.dot(X,theta))\n",
    "    tmp = np.copy(theta)\n",
    "    tmp[0] = 0\n",
    "    reg = _lambda*tmp /m\n",
    "\n",
    "    return ((1 / m) * X.T.dot(h - y)) + reg\n",
    "\n",
    "#Optimal theta (which minimizes the regressionCostFunction)\n",
    "def logisticRegression(X, y, theta):\n",
    "    result = op.minimize(fun = regCostFunction, x0 = theta, args = (X, y),\n",
    "                         method = 'TNC', jac = regGradient)\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the model\n",
    "def regLossModel(X,y):\n",
    "    n = kernel_train.shape[1]\n",
    "    optTheta = logisticRegression(kernel_train, y, np.zeros((n ,1)))\n",
    "    return optTheta\n",
    "\n",
    "# do predictions\n",
    "def regLossPredict(X, optTheta):\n",
    "    pred = np.round(sigmoid(X.dot(optTheta.T))).astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load training samples\n",
    "X_train_0 = pd.read_csv(\"Xtr0.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_train_1 = pd.read_csv(\"Xtr1.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_train_2 = pd.read_csv(\"Xtr2.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "\n",
    "#load training labels\n",
    "\n",
    "y_train_0 = pd.read_csv(\"Ytr0.csv\")[\"Bound\"]\n",
    "y_train_0 = pd.read_csv(\"Ytr1.csv\")[\"Bound\"]\n",
    "y_train_0 = pd.read_csv(\"Ytr2.csv\")[\"Bound\"]\n",
    "\n",
    "#testing samples\n",
    "X_test_0 = pd.read_csv(\"Xte0.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_test_1 = pd.read_csv(\"Xte1.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_test_2 = pd.read_csv(\"Xte2.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing training gram matrix\n",
    "kernel_train_0 = computeKernelMatrix(X_train_0,X_train_0, 3)\n",
    "kernel_train_1 = computeKernelMatrix(X_train_1,X_train_1, 3)\n",
    "kernel_train_2 = computeKernelMatrix(X_train_2,X_train_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computing testing gram matrix\n",
    "kernel_test_0 = computeKernelMatrix(X_test_0, X_train_0, 3)\n",
    "kernel_test_1 = computeKernelMatrix(X_test_1, X_train_1, 3)\n",
    "kernel_test_2 = computeKernelMatrix(X_test_2, X_train_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optTheta_0 = regLossModel(kernel_train_0,y_train_0)\n",
    "predictions0 = regLossPredict(kernel_test_0, optTheta_0)\n",
    "\n",
    "optTheta_1 = regLossModel(kernel_train_1,y_train_1)\n",
    "predictions1 = regLossPredict(kernel_test_1, optTheta_1)\n",
    "\n",
    "optTheta_2 = regLossModel(kernel_train_2,y_train_2)\n",
    "predictions2 = regLossPredict(kernel_test_2, optTheta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
