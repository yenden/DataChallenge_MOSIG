{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of SPectrum Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#spectrum kernel implem\n",
    "#saw it in ALM course\n",
    "\n",
    "\n",
    "def getSubString(mString, spectrum):\n",
    "    \"\"\"\n",
    "    get substrings of length spectrum\n",
    "    \n",
    "    Attributes:\n",
    "        mstring: the string to subdivise\n",
    "        spectrum : the length of the substrings\n",
    "    return :\n",
    "        substrings of length spectrum\n",
    "    \"\"\"\n",
    "    tmpList = []\n",
    "    mString = mString.lower()\n",
    "    if (spectrum == 0):\n",
    "        tmpList = ['']\n",
    "    else:\n",
    "        for i in range(len(mString)-spectrum+1):\n",
    "            mStringRes = ''\n",
    "            for j in range(spectrum):\n",
    "                mStringRes += mString[i+j]\n",
    "            tmpList.append(mStringRes)\n",
    "    return tmpList\n",
    "\n",
    "def pSpectrumKernelFunction(mString1, mString2, spectrum):\n",
    "    \"\"\"\n",
    "    compute the spectrum kernel of two strings\n",
    "   \n",
    "    Attributes:\n",
    "        mstring1 : the first string\n",
    "        mstring2: the second string\n",
    "        spectrum : the length of substrings(spectrum used)\n",
    "    return :\n",
    "        spectrum kernel value\n",
    "    \"\"\"\n",
    "    \n",
    "    subString1 = getSubString(mString1, spectrum)\n",
    "    subString2 = getSubString(mString2, spectrum)\n",
    "    kernel = 0\n",
    "    for i in subString1:\n",
    "        for j in subString2:\n",
    "            if (i==j):\n",
    "                kernel += 1\n",
    "    return kernel\n",
    "\n",
    "def _gram_matrix_element(mString1, mString2, spectrum, sdkvalue1, sdkvalue2):\n",
    "    \"\"\"\n",
    "        compute the element K(i,j) of a gram matrix\n",
    "        normalize spectrum kernel are used Knorm(i,j) = K(i,j)/(K(i,i)*K(j,j))^O.5\n",
    "        \n",
    "        Attributes:\n",
    "            mstring1, mstring2: strings for which we compute the kernel\n",
    "            sdkvalue1, sdvalue2: K(mString1,mString1) and K(mString2,mString2) are diagonal \n",
    "                                  elements of K\n",
    "    \"\"\"\n",
    "    if mString1 == mString2:\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            return pSpectrumKernelFunction(mString1, mString2, spectrum) / \\\n",
    "                       (sdkvalue1 * sdkvalue2) ** 0.5\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Maximal subsequence length is less or equal to documents' minimal length.\"\n",
    "                      \"You should decrease it\")\n",
    "            sys.exit(2)\n",
    "            \n",
    "def computeKernelMatrix(X1, X2, spectrum):\n",
    "    \"\"\"\n",
    "    spectrum Kernel computation\n",
    "    Attributes:\n",
    "        param X: list of DNAs (m rows, 1 column); each row is a single DNA (string)\n",
    "        return: Gram matrix for the given parameters\n",
    "    \"\"\"\n",
    "    len_X1 = len(X1)\n",
    "    len_X2 = len(X2)\n",
    "    \n",
    "    # numpy array of Gram matrix\n",
    "    gram_matrix = np.zeros((len_X1, len_X2), dtype=np.float32)\n",
    "    sim_docs_kernel_value = {}\n",
    "    #when lists of documents are identical\n",
    "    if (X1==X2).all():\n",
    "    #store K(s,s) values in dictionary to avoid recalculations\n",
    "        for i in range(len_X1):\n",
    "#             print(\"ii\",i)\n",
    "            sim_docs_kernel_value[i] = pSpectrumKernelFunction(X1.item(i), X1.item(i), spectrum)\n",
    "        #calculate Gram matrix\n",
    "        for i in range(len_X1):\n",
    "#             print(\"i\",i)\n",
    "            for j in range(i, len_X2):\n",
    "                if(i==j):\n",
    "                    gram_matrix[i, j] = 1.0\n",
    "                else:\n",
    "                    gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), spectrum, sim_docs_kernel_value[i]\n",
    "                                                                 ,sim_docs_kernel_value[j])\n",
    "            #using symmetry\n",
    "                    gram_matrix[j, i] = gram_matrix[i, j]\n",
    "        \n",
    "    #when lists of documents are not identical but of the same length\n",
    "    elif len_X1 == len_X2:\n",
    "        sim_docs_kernel_value[1] = {}\n",
    "        sim_docs_kernel_value[2] = {}\n",
    "        #store K(s,s) values in dictionary to avoid recalculations\n",
    "        for i in range(len_X1):\n",
    "            sim_docs_kernel_value[1][i] = pSpectrumKernelFunction(X1.item(i), X1.item(i), spectrum)\n",
    "        for i in range(len_X2):\n",
    "            sim_docs_kernel_value[2][i] = pSpectrumKernelFunction(X2.item(i), X2.item(i), spectrum)\n",
    "        #calculate Gram matrix\n",
    "        for i in range(len_X1):\n",
    "#             print(\"ilen\",i)\n",
    "            for j in range(i, len_X2):\n",
    "                gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), spectrum, sim_docs_kernel_value[1][i],\n",
    "                                                             sim_docs_kernel_value[2][j])\n",
    "        #using symmetry\n",
    "                gram_matrix[j, i] = gram_matrix[i, j]\n",
    "    \n",
    "    #when lists of documents are neither identical nor of the same length\n",
    "    else:\n",
    "        sim_docs_kernel_value[1] = {}\n",
    "        sim_docs_kernel_value[2] = {}\n",
    "        min_dimens = min(len_X1, len_X2)\n",
    "        #store K(s,s) values in dictionary to avoid recalculations\n",
    "        for i in range(len_X1):\n",
    "            sim_docs_kernel_value[1][i] = pSpectrumKernelFunction(X1.item(i), X1.item(i), spectrum)\n",
    "        for i in range(len_X2):\n",
    "            sim_docs_kernel_value[2][i] = pSpectrumKernelFunction(X2.item(i), X2.item(i), spectrum)\n",
    "        #calculate Gram matrix for square part of rectangle matrix\n",
    "        for i in range(min_dimens):\n",
    "#             print(\"ielse1\",i)\n",
    "            for j in range(i, min_dimens):\n",
    "                gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), spectrum, sim_docs_kernel_value[1][i],\n",
    "                                                             sim_docs_kernel_value[2][j])\n",
    "                    #using symmetry\n",
    "                gram_matrix[j, i] = gram_matrix[i, j]\n",
    "\n",
    "        #if more rows than columns\n",
    "        if len_X1 > len_X2:\n",
    "            for i in range(min_dimens, len_X1):\n",
    "                for j in range(len_X2):\n",
    "                    gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j), sim_docs_kernel_value[1][i],\n",
    "                                                                 sim_docs_kernel_value[2][j])\n",
    "        #if more columns than rows\n",
    "            \n",
    "        else:\n",
    "            for i in range(len_X1):\n",
    "#                 print(\"ielse2\",i)\n",
    "                for j in range(min_dimens, len_X2):\n",
    "                    gram_matrix[i, j] = _gram_matrix_element(X1.item(i), X2.item(j),spectrum, sim_docs_kernel_value[1][i],\n",
    "                                                                 sim_docs_kernel_value[2][j])\n",
    "    return gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression implementation\n",
    "from scipy import optimize as op #I read that we can use optimization library so... \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "#Regularized cost function\n",
    "def regCostFunction(theta, X, y, _lambda = 0.01):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X,theta))\n",
    "    tmp = np.copy(theta)\n",
    "    tmp[0] = 0 \n",
    "    reg = (_lambda/(2*m)) * np.sum(tmp**2)\n",
    "\n",
    "    return (1 / m) * (-y.T.dot(np.log(h)) - (1 - y).T.dot(np.log(1 - h))) + reg\n",
    "\n",
    "#Regularized gradient function\n",
    "def regGradient(theta, X, y, _lambda = 0.1):\n",
    "    m, n = X.shape\n",
    "    theta = theta.reshape((n, 1))\n",
    "    y = y.values.reshape((m, 1))\n",
    "    h = sigmoid(np.dot(X,theta))\n",
    "    tmp = np.copy(theta)\n",
    "    tmp[0] = 0\n",
    "    reg = _lambda*tmp /m\n",
    "\n",
    "    return ((1 / m) * X.T.dot(h - y)) + reg\n",
    "\n",
    "#Optimal theta (which minimizes the regressionCostFunction)\n",
    "def logisticRegression(X, y, theta):\n",
    "    result = op.minimize(fun = regCostFunction, x0 = theta, args = (X, y),\n",
    "                         method = 'TNC', jac = regGradient)\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the model\n",
    "def regLossModel(X,y):\n",
    "    n = kernel_train.shape[1]\n",
    "    optTheta = logisticRegression(kernel_train, y, np.zeros((n ,1)))\n",
    "    return optTheta\n",
    "\n",
    "# do predictions\n",
    "def regLossPredict(X, optTheta):\n",
    "    pred = np.round(sigmoid(X.dot(optTheta.T))).astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Xtr0.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bfe18c9a2d66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Load training samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Xtr0.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX_train_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Xtr1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_train_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Xtr2.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'Xtr0.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load training samples\n",
    "X_train_0 = pd.read_csv(\"Xtr0.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_train_1 = pd.read_csv(\"Xtr1.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_train_2 = pd.read_csv(\"Xtr2.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "\n",
    "#load training labels\n",
    "\n",
    "y_train_0 = pd.read_csv(\"Ytr0.csv\")[\"Bound\"]\n",
    "y_train_0 = pd.read_csv(\"Ytr1.csv\")[\"Bound\"]\n",
    "y_train_0 = pd.read_csv(\"Ytr2.csv\")[\"Bound\"]\n",
    "\n",
    "#testing samples\n",
    "X_test_0 = pd.read_csv(\"Xte0.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_test_1 = pd.read_csv(\"Xte1.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)\n",
    "X_test_2 = pd.read_csv(\"Xte2.csv\", header= None, delim_whitespace= True).as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computing training gram matrix\n",
    "kernel_train_0 = computeKernelMatrix(X_train_0,X_train_0, 3)\n",
    "kernel_train_1 = computeKernelMatrix(X_train_1,X_train_1, 3)\n",
    "kernel_train_2 = computeKernelMatrix(X_train_2,X_train_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computing testing gram matrix\n",
    "kernel_test_0 = computeKernelMatrix(X_test_0, X_train_0, 3)\n",
    "kernel_test_1 = computeKernelMatrix(X_test_1, X_train_1, 3)\n",
    "kernel_test_2 = computeKernelMatrix(X_test_2, X_train_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optTheta_0 = regLossModel(kernel_train_0,y_train_0)\n",
    "predictions0 = regLossPredict(kernel_test_0, optTheta_0)\n",
    "\n",
    "optTheta_1 = regLossModel(kernel_train_1,y_train_1)\n",
    "predictions1 = regLossPredict(kernel_test_1, optTheta_1)\n",
    "\n",
    "optTheta_2 = regLossModel(kernel_train_2,y_train_2)\n",
    "predictions2 = regLossPredict(kernel_test_2, optTheta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
